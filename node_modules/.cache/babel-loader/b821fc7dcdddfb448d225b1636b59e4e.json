{"ast":null,"code":"// import { put, all, call, select, takeEvery } from 'redux-saga/effects';\n// import {\n//   types,\n//   getNerData,\n//   getRelationData,\n// } from '../reducers/editstate';\n// import axios from 'axios';\n// import { initialLayout } from '../utils/layout';\n// import { initialOverviewLayout } from '../utils/overviewLayout.js';\n// // Posts the updated relation data to the backend and returns the updated network data.\n// const apiPostNetwork = (data) => {\n//   const formData = new FormData();\n//   formData.append('relationData', JSON.stringify(data));\n//   return axios.post('http://localhost:5000/updateNetwork', formData);\n// };\n// // Dispatches the action UPDATED_NETWORK_DATA to update the redux store with the new network data based on the file that was changed.\n// function* updateNetworkHelper({ data, currentFileName }) {\n//   const res = yield call(apiPostNetwork, data);\n//   const networkData = res.data;\n//   yield put({\n//     type: types.UPDATED_NETWORK_DATA,\n//     payload: networkData,\n//     currentFileName: currentFileName,\n//   });\n// }\n// // Dispatches the action UPLOADED_CORPUS_DATA to update the redux store with the new corpus data.\n// function* setCorpusData({ data }) {\n//   yield put({\n//     type: types.UPLOADED_CORPUS_DATA,\n//     payload: data,\n//   });\n// }\n// // Dispatches the action SET_FILENAMES and SET_LAYOUT based on the object keys of the corpus data.\n// function* setFileNames({ data }) {\n//   const fileNames = Object.keys(data);\n//   yield put({\n//     type: types.SET_FILENAMES,\n//     payload: fileNames,\n//   });\n//   var layouts = {};\n//   if (fileNames.length > 1) {\n//     fileNames\n//       .filter((e) => e !== 'Overview')\n//       .forEach((e) => (layouts[e] = initialLayout));\n//     layouts['Overview'] = initialOverviewLayout;\n//   } else {\n//     layouts[fileNames[0]] = initialLayout;\n//   }\n//   yield put({\n//     type: types.SET_LAYOUT,\n//     payload: layouts,\n//   });\n// }\n// // Posts the uploaded files to the backend and returns the output.\n// const apiPost = (payload) => {\n//   const formData = new FormData();\n//   console.log(\"payload: \", payload)\n//   var fileNames = [];\n//   for (var i = 0; i < payload.files.length; i++) {\n//     formData.append('file'.concat(i.toString()), payload.files[i]);\n//     fileNames.push(payload.files[i].name);\n//   }\n//   fileNames = JSON.stringify(fileNames);\n//   formData.append('fileNames', fileNames);\n//   formData.append('length', payload.files.length);\n//   console.log(\"payload files \", payload.files)\n//   var configFile = JSON.stringify(payload.config)\n//   formData.append('config', configFile);\n//   console.log(\"config: \", configFile)\n//   // inspect formData\n//   for (var pair of formData.entries()) {\n//       console.log(pair[0]+ ', ' + pair[1]); \n//   }\n//   return axios.post('http://uploadfile-sme-project.apps.kw.projectinnovate.sg/uploadFile', formData);\n// };\n// // Posts the JSON document to the backend and returns the output.\n// const apiPostJson = (payload) => {\n//   const formData = new FormData();\n//   formData.append('existingFile', payload);\n//   // 'http://loadexistingfile-alice.apps.8d5714affbde4fa6828a.southeastasia.azmosa.io/loadExistingFile'\n//   return axios.post('http://loadexistingfile-sme-project.apps.kw.projectinnovate.sg/loadExistingFile', formData);\n// };\n// // Posts the ObjectID of the document and returns the output from the MongoDB entry corresponding\n// // to that ObjectID.\n// const apiPostDb = (payload) => {\n//   // 'http://loaddbfile-alice.apps.8d5714affbde4fa6828a.southeastasia.azmosa.io/loadDbFile'\n//   return axios.post('http://localhost:5000/loadDbFile', {ID: payload});\n// }\n// // Posts the webscape request to the backend and returns the output.\n// const apiScrape = (payload) => {\n//   /*\n//   Have to convert the dictionary to a compatible object form for Flask to receive properly\n//   however, an array will still be received as a string by Flask so\n//   manipulate the data form at the scraper side instead\n//   see here for more info https://stackoverflow.com/questions/54892531/axios-data-coming-up-as-immutablemultidict-when-sent-to-flask-post-route-bu\n//   */\n//   const params = new URLSearchParams();\n//   const keys = Object.keys(payload);\n//   for (let key of keys) {\n//       params.append(key, payload[key]);\n//   }\n//   //return axios.post('http://localhost:5000/scrape', params);\n//   return axios.post('http://scrape-sme-project.apps.kw.projectinnovate.sg/scrape', params);\n//   };\n// var download_url = null;\n// export function get_download_url() {\n//   return download_url;\n// }\n// // Uploads the data to the backend to call the respective webscraper API in the backend\n// // dispatches the action SCRAPING_SUCCESS or SCRAPING_FAILURE depending\n// // on the status of the upload.\n// export function* scrapeData({ payload }) {\n//   try {\n//     let res;\n//     console.log(payload);\n//     res = yield call(apiScrape, payload);\n//     console.log('response', res);\n//     download_url = res.data;\n//     yield put({\n//       type: types.SCRAPING_SUCCESS,\n//     });\n//   } catch (error) {\n//     yield put({\n//       type: types.SCRAPING_FAILURE,\n//     });\n//     console.log('Error while scraping', error);\n//   }\n// }\n// // Uploads the data to the backend based on the input type and\n// // dispatches the action UPLOAD_SUCCESS or UPLOAD_FAILURE depending\n// // on the status of the upload.\n// // If the document uploaded is an existing one (JSON or MongoDB ObjectID),\n// // the function dispatches the action SET_EXISTING_DOCUMENT.\n// export function* uploadData({ payload }) {\n//   try {\n//     let res;\n//     if (payload.existing) {\n//       if (payload.docId) {\n//         res = yield call(apiPostDb, payload.docId);\n//         console.log(payload)\n//         console.log(res)\n//       } else {\n//         res = yield call(apiPostJson, payload.files);\n//       }\n//       console.log(payload)\n//       console.log(res)\n//       const existingData = res.data;\n//       // Remove bugs related to network graph when loading existing file\n//       existingData.fileNames.forEach((document) => {\n//         console.log(existingData);\n//         console.log(existingData.corpusData[document]);\n//         if (existingData.corpusData[document].network.links.length > 0) {\n//           if (existingData.corpusData[document].network.links[0].source.id) {\n//             existingData.corpusData[document].network.links.forEach((link) => {\n//               link.source = link.source.id;\n//               link.target = link.target.id;\n//               delete link.__indexColor;\n//               delete link.__controlPoints;\n//               delete link.__photons;\n//               delete link.index;\n//             });\n//             existingData.corpusData[document].network.nodes.forEach((node) => {\n//               delete node.index;\n//               delete node.x;\n//               delete node.y;\n//               delete node.vx;\n//               delete node.vy;\n//               delete node.__indexColor;\n//             });\n//           }\n//         }\n//       });\n//       yield put({\n//         type: types.SET_EXISTING_DOCUMENT,\n//         payload: existingData,\n//       });\n//     } else {\n//       console.log(\"apipost payload\", payload);\n//       res = yield call(apiPost, payload);\n//       const newData = res.data;\n//       if (Object.keys(newData).length === 0) {\n//         throw new Error('Document could not be processed');\n//       }\n//       // Remove bugs related to network graph when generating new data\n//       Object.keys(newData.corpusData).forEach((document) => {\n//         console.log(newData);\n//         console.log(newData.corpusData[document]);\n//         if (newData.corpusData[document].network.links.length > 0) {\n//           if (newData.corpusData[document].network.links[0].source.id) {\n//             newData.corpusData[document].network.links.forEach((link) => {\n//               link.source = link.source.id;\n//               link.target = link.target.id;\n//               delete link.__indexColor;\n//               delete link.__controlPoints;\n//               delete link.__photons;\n//               delete link.index;\n//             });\n//             newData.corpusData[document].network.nodes.forEach((node) => {\n//               delete node.index;\n//               delete node.x;\n//               delete node.y;\n//               delete node.vx;\n//               delete node.vy;\n//               delete node.__indexColor;\n//             });\n//           }\n//         }\n//       });\n//       const args = { data: newData.corpusData };\n//       yield all([call(setCorpusData, args), call(setFileNames, args)]);\n//     }\n//     yield put({\n//       type: types.UPLOAD_SUCCESS,\n//     });\n//   } catch (error) {\n//     yield put({\n//       type: types.UPLOAD_FAILURE,\n//     });\n//     console.log('ERROR', error);\n//   }\n// }\n// // Dispatches the action UPDATED_NER_DATA to update the redux store with the new NER data based on the file that was changed.\n// // // Updates the relation and network data based on the new changes.\n// function* updateNer({ payload }) {\n//   const { newNer, nerToRelation, currentFileName } = payload;\n//   const currentNerData = yield select(getNerData, [currentFileName]);\n//   const text = currentNerData.text;\n//   const currentRelationData = yield select(getRelationData, currentFileName);\n//   var newRelationData;\n//   if (nerToRelation[3] === 'DELETE') {\n//     newRelationData = currentRelationData.filter((e) => {\n//       return (\n//         (e.e1 !== nerToRelation[0] || e.e1_id !== nerToRelation[1]) &&\n//         (e.e2 !== nerToRelation[0] || e.e2_id !== nerToRelation[1])\n//       );\n//     });\n//   } else {\n//     newRelationData = currentRelationData.map((e) => {\n//       if (e.e1 === nerToRelation[0] && e.e1_id === nerToRelation[1]) {\n//         e.e1_label = nerToRelation[2];\n//       } else if (e.e2 === nerToRelation[0] && e.e2_id === nerToRelation[1]) {\n//         e.e2_label = nerToRelation[2];\n//       }\n//       return e;\n//     });\n//   }\n//   yield put({\n//     type: types.UPDATED_NER_DATA,\n//     payload: {\n//       text: text,\n//       ents: newNer,\n//     },\n//     currentFileName: currentFileName,\n//   });\n//   const args = { data: newRelationData, currentFileName: currentFileName };\n//   yield all([\n//     call(updateRelationHelper, args),\n//     call(updateNetworkHelper, args),\n//   ]);\n// }\n// // Dispatches the action UPDATED_RELATION_DATA to update the redux store with the new relation data based on the file that was changed.\n// function* updateRelationHelper({ data, currentFileName }) {\n//   yield put({\n//     type: types.UPDATED_RELATION_DATA,\n//     payload: data,\n//     currentFileName: currentFileName,\n//   });\n// }\n// // Updates the relation and network data based on the new changes.\n// function* updateRelation({ payload }) {\n//   const { newRelation, currentFileName } = payload;\n//   const args = { data: newRelation, currentFileName: currentFileName };\n//   yield all([\n//     call(updateRelationHelper, args),\n//     call(updateNetworkHelper, args),\n//   ]);\n// }\n// export default [\n//   takeEvery(types.UPLOADING_DATA, uploadData),\n//   takeEvery(types.SCRAPING_DATA, scrapeData),\n//   takeEvery(types.UPDATING_NER_DATA, updateNer),\n//   takeEvery(types.UPDATING_RELATION_DATA, updateRelation),\n// ];","map":{"version":3,"names":[],"sources":["C:/1.Regine/PDA-APP/frontend/src/sagas/editstate.js"],"sourcesContent":["// import { put, all, call, select, takeEvery } from 'redux-saga/effects';\n// import {\n//   types,\n//   getNerData,\n//   getRelationData,\n// } from '../reducers/editstate';\n// import axios from 'axios';\n// import { initialLayout } from '../utils/layout';\n// import { initialOverviewLayout } from '../utils/overviewLayout.js';\n\n// // Posts the updated relation data to the backend and returns the updated network data.\n// const apiPostNetwork = (data) => {\n//   const formData = new FormData();\n//   formData.append('relationData', JSON.stringify(data));\n//   return axios.post('http://localhost:5000/updateNetwork', formData);\n// };\n\n// // Dispatches the action UPDATED_NETWORK_DATA to update the redux store with the new network data based on the file that was changed.\n// function* updateNetworkHelper({ data, currentFileName }) {\n//   const res = yield call(apiPostNetwork, data);\n//   const networkData = res.data;\n//   yield put({\n//     type: types.UPDATED_NETWORK_DATA,\n//     payload: networkData,\n//     currentFileName: currentFileName,\n//   });\n// }\n\n\n// // Dispatches the action UPLOADED_CORPUS_DATA to update the redux store with the new corpus data.\n// function* setCorpusData({ data }) {\n//   yield put({\n//     type: types.UPLOADED_CORPUS_DATA,\n//     payload: data,\n//   });\n// }\n\n// // Dispatches the action SET_FILENAMES and SET_LAYOUT based on the object keys of the corpus data.\n// function* setFileNames({ data }) {\n//   const fileNames = Object.keys(data);\n//   yield put({\n//     type: types.SET_FILENAMES,\n//     payload: fileNames,\n//   });\n//   var layouts = {};\n//   if (fileNames.length > 1) {\n//     fileNames\n//       .filter((e) => e !== 'Overview')\n//       .forEach((e) => (layouts[e] = initialLayout));\n//     layouts['Overview'] = initialOverviewLayout;\n//   } else {\n//     layouts[fileNames[0]] = initialLayout;\n//   }\n//   yield put({\n//     type: types.SET_LAYOUT,\n//     payload: layouts,\n//   });\n// }\n\n// // Posts the uploaded files to the backend and returns the output.\n// const apiPost = (payload) => {\n//   const formData = new FormData();\n//   console.log(\"payload: \", payload)\n//   var fileNames = [];\n//   for (var i = 0; i < payload.files.length; i++) {\n//     formData.append('file'.concat(i.toString()), payload.files[i]);\n//     fileNames.push(payload.files[i].name);\n//   }\n//   fileNames = JSON.stringify(fileNames);\n//   formData.append('fileNames', fileNames);\n//   formData.append('length', payload.files.length);\n\n//   console.log(\"payload files \", payload.files)\n  \n//   var configFile = JSON.stringify(payload.config)\n//   formData.append('config', configFile);\n\n//   console.log(\"config: \", configFile)\n\n//   // inspect formData\n//   for (var pair of formData.entries()) {\n//       console.log(pair[0]+ ', ' + pair[1]); \n//   }\n\n//   return axios.post('http://uploadfile-sme-project.apps.kw.projectinnovate.sg/uploadFile', formData);\n// };\n\n// // Posts the JSON document to the backend and returns the output.\n// const apiPostJson = (payload) => {\n//   const formData = new FormData();\n//   formData.append('existingFile', payload);\n//   // 'http://loadexistingfile-alice.apps.8d5714affbde4fa6828a.southeastasia.azmosa.io/loadExistingFile'\n//   return axios.post('http://loadexistingfile-sme-project.apps.kw.projectinnovate.sg/loadExistingFile', formData);\n// };\n\n// // Posts the ObjectID of the document and returns the output from the MongoDB entry corresponding\n// // to that ObjectID.\n// const apiPostDb = (payload) => {\n//   // 'http://loaddbfile-alice.apps.8d5714affbde4fa6828a.southeastasia.azmosa.io/loadDbFile'\n//   return axios.post('http://localhost:5000/loadDbFile', {ID: payload});\n// }\n\n\n// // Posts the webscape request to the backend and returns the output.\n// const apiScrape = (payload) => {\n//   /*\n//   Have to convert the dictionary to a compatible object form for Flask to receive properly\n//   however, an array will still be received as a string by Flask so\n//   manipulate the data form at the scraper side instead\n//   see here for more info https://stackoverflow.com/questions/54892531/axios-data-coming-up-as-immutablemultidict-when-sent-to-flask-post-route-bu\n//   */\n  \n//   const params = new URLSearchParams();\n//   const keys = Object.keys(payload);\n//   for (let key of keys) {\n//       params.append(key, payload[key]);\n//   }\n\n//   //return axios.post('http://localhost:5000/scrape', params);\n//   return axios.post('http://scrape-sme-project.apps.kw.projectinnovate.sg/scrape', params);\n//   };\n\n\n// var download_url = null;\n\n// export function get_download_url() {\n//   return download_url;\n// }\n\n// // Uploads the data to the backend to call the respective webscraper API in the backend\n// // dispatches the action SCRAPING_SUCCESS or SCRAPING_FAILURE depending\n// // on the status of the upload.\n// export function* scrapeData({ payload }) {\n//   try {\n//     let res;\n//     console.log(payload);\n//     res = yield call(apiScrape, payload);\n\n//     console.log('response', res);\n//     download_url = res.data;\n\n//     yield put({\n//       type: types.SCRAPING_SUCCESS,\n//     });\n//   } catch (error) {\n//     yield put({\n//       type: types.SCRAPING_FAILURE,\n//     });\n//     console.log('Error while scraping', error);\n//   }\n// }\n \n\n// // Uploads the data to the backend based on the input type and\n// // dispatches the action UPLOAD_SUCCESS or UPLOAD_FAILURE depending\n// // on the status of the upload.\n// // If the document uploaded is an existing one (JSON or MongoDB ObjectID),\n// // the function dispatches the action SET_EXISTING_DOCUMENT.\n// export function* uploadData({ payload }) {\n//   try {\n//     let res;\n//     if (payload.existing) {\n//       if (payload.docId) {\n//         res = yield call(apiPostDb, payload.docId);\n//         console.log(payload)\n//         console.log(res)\n//       } else {\n//         res = yield call(apiPostJson, payload.files);\n//       }\n//       console.log(payload)\n//       console.log(res)\n//       const existingData = res.data;\n\n//       // Remove bugs related to network graph when loading existing file\n//       existingData.fileNames.forEach((document) => {\n//         console.log(existingData);\n//         console.log(existingData.corpusData[document]);\n//         if (existingData.corpusData[document].network.links.length > 0) {\n//           if (existingData.corpusData[document].network.links[0].source.id) {\n//             existingData.corpusData[document].network.links.forEach((link) => {\n//               link.source = link.source.id;\n//               link.target = link.target.id;\n//               delete link.__indexColor;\n//               delete link.__controlPoints;\n//               delete link.__photons;\n//               delete link.index;\n//             });\n\n//             existingData.corpusData[document].network.nodes.forEach((node) => {\n//               delete node.index;\n//               delete node.x;\n//               delete node.y;\n//               delete node.vx;\n//               delete node.vy;\n//               delete node.__indexColor;\n//             });\n//           }\n//         }\n//       });\n\n//       yield put({\n//         type: types.SET_EXISTING_DOCUMENT,\n//         payload: existingData,\n//       });\n//     } else {\n//       console.log(\"apipost payload\", payload);\n//       res = yield call(apiPost, payload);\n//       const newData = res.data;\n//       if (Object.keys(newData).length === 0) {\n//         throw new Error('Document could not be processed');\n//       }\n\n//       // Remove bugs related to network graph when generating new data\n//       Object.keys(newData.corpusData).forEach((document) => {\n//         console.log(newData);\n//         console.log(newData.corpusData[document]);\n//         if (newData.corpusData[document].network.links.length > 0) {\n//           if (newData.corpusData[document].network.links[0].source.id) {\n//             newData.corpusData[document].network.links.forEach((link) => {\n//               link.source = link.source.id;\n//               link.target = link.target.id;\n//               delete link.__indexColor;\n//               delete link.__controlPoints;\n//               delete link.__photons;\n//               delete link.index;\n//             });\n\n//             newData.corpusData[document].network.nodes.forEach((node) => {\n//               delete node.index;\n//               delete node.x;\n//               delete node.y;\n//               delete node.vx;\n//               delete node.vy;\n//               delete node.__indexColor;\n//             });\n//           }\n//         }\n//       });\n//       const args = { data: newData.corpusData };\n//       yield all([call(setCorpusData, args), call(setFileNames, args)]);\n//     }\n//     yield put({\n//       type: types.UPLOAD_SUCCESS,\n//     });\n//   } catch (error) {\n//     yield put({\n//       type: types.UPLOAD_FAILURE,\n//     });\n//     console.log('ERROR', error);\n//   }\n// }\n\n// // Dispatches the action UPDATED_NER_DATA to update the redux store with the new NER data based on the file that was changed.\n// // // Updates the relation and network data based on the new changes.\n// function* updateNer({ payload }) {\n//   const { newNer, nerToRelation, currentFileName } = payload;\n//   const currentNerData = yield select(getNerData, [currentFileName]);\n//   const text = currentNerData.text;\n//   const currentRelationData = yield select(getRelationData, currentFileName);\n//   var newRelationData;\n//   if (nerToRelation[3] === 'DELETE') {\n//     newRelationData = currentRelationData.filter((e) => {\n//       return (\n//         (e.e1 !== nerToRelation[0] || e.e1_id !== nerToRelation[1]) &&\n//         (e.e2 !== nerToRelation[0] || e.e2_id !== nerToRelation[1])\n//       );\n//     });\n//   } else {\n//     newRelationData = currentRelationData.map((e) => {\n//       if (e.e1 === nerToRelation[0] && e.e1_id === nerToRelation[1]) {\n//         e.e1_label = nerToRelation[2];\n//       } else if (e.e2 === nerToRelation[0] && e.e2_id === nerToRelation[1]) {\n//         e.e2_label = nerToRelation[2];\n//       }\n//       return e;\n//     });\n//   }\n\n//   yield put({\n//     type: types.UPDATED_NER_DATA,\n//     payload: {\n//       text: text,\n//       ents: newNer,\n//     },\n//     currentFileName: currentFileName,\n//   });\n//   const args = { data: newRelationData, currentFileName: currentFileName };\n//   yield all([\n//     call(updateRelationHelper, args),\n//     call(updateNetworkHelper, args),\n//   ]);\n// }\n\n// // Dispatches the action UPDATED_RELATION_DATA to update the redux store with the new relation data based on the file that was changed.\n// function* updateRelationHelper({ data, currentFileName }) {\n//   yield put({\n//     type: types.UPDATED_RELATION_DATA,\n//     payload: data,\n//     currentFileName: currentFileName,\n//   });\n// }\n\n// // Updates the relation and network data based on the new changes.\n// function* updateRelation({ payload }) {\n//   const { newRelation, currentFileName } = payload;\n//   const args = { data: newRelation, currentFileName: currentFileName };\n//   yield all([\n//     call(updateRelationHelper, args),\n//     call(updateNetworkHelper, args),\n//   ]);\n// }\n\n// export default [\n//   takeEvery(types.UPLOADING_DATA, uploadData),\n//   takeEvery(types.SCRAPING_DATA, scrapeData),\n//   takeEvery(types.UPDATING_NER_DATA, updateNer),\n//   takeEvery(types.UPDATING_RELATION_DATA, updateRelation),\n// ];\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAGA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA"},"metadata":{},"sourceType":"module"}